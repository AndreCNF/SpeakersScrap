{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Newspaper\n",
    "\n",
    "Using the newspaper python library and parts of the code from https://holwech.github.io/blog/Automatic-news-scraper/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import newspaper\n",
    "from tqdm import tqdm_notebook\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/AndreCNF/OneDrive/TEDxULisboa/SpeakersScrap/env/bin/python3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NY Times article example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nytimes.com/2017/07/14/world/asia/china-liu-xiaobo-censorship-internet.html'\n",
    "article = newspaper.Article(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.top_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_paper = newspaper.build('http://cnn.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in cnn_paper.articles:\n",
    "    print(article.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in cnn_paper.category_urls():\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article = cnn_paper.articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.top_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing\n",
    "cnn_article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_article.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifter articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newspaper.languages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_paper = newspaper.build('https://shifter.sapo.pt/', language='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for article in shifter_paper.articles:\n",
    "    print(article.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in shifter_paper.category_urls():\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article = shifter_paper.articles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.parse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.top_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Natural Language Processing\n",
    "shifter_article.nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter_article.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with multiple news sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read yaml configuration file, with the requested news sources\n",
    "with open(\"/Users/AndreCNF/OneDrive/TEDxULisboa/SpeakersScrap/configs/andreferreira_yaml_0.1.yaml\", 'r') as stream:\n",
    "    try:\n",
    "        config_yaml = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIC Noticias\n",
      "Expresso\n",
      "Jornal de Noticias\n",
      "MAGG\n",
      "Sapo\n",
      "TVI24\n",
      "Observador\n",
      "Diario de Noticias\n",
      "Publico\n",
      "Tecnico\n",
      "ULisboa\n",
      "Exame\n",
      "Noticias ao Minuto\n",
      "Jornal de Negocios\n",
      "Euronews\n",
      "ar magazine\n",
      "Shifter\n",
      "RTP\n"
     ]
    }
   ],
   "source": [
    "for key, vals in config_yaml['news_sources'].items():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the limit for number of articles to download\n",
    "LIMIT = 4\n",
    "\n",
    "data = {}\n",
    "data['newspapers'] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "\n",
    "# Iterate through each news company\n",
    "for company, value in tqdm_notebook(companies.items()):\n",
    "    print(\"Building site for \", company)\n",
    "    paper = newspaper.build(value['link'], memoize_articles=False)\n",
    "    newsPaper = {\n",
    "        \"link\": value['link'],\n",
    "        \"articles\": []\n",
    "    }\n",
    "    noneTypeCount = 0\n",
    "    for content in paper.articles:\n",
    "        if count > LIMIT:\n",
    "            break\n",
    "        try:\n",
    "            content.download()\n",
    "            content.parse()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"continuing...\")\n",
    "            continue\n",
    "        # Again, for consistency, if there is no found publish date the article will be skipped.\n",
    "        # After 10 downloaded articles from the same newspaper without publish date, the company will be skipped.\n",
    "        if content.publish_date is None:\n",
    "            print(count, \" Article has date of type None...\")\n",
    "            noneTypeCount = noneTypeCount + 1\n",
    "            if noneTypeCount > 10:\n",
    "                print(\"Too many noneType dates, aborting...\")\n",
    "                noneTypeCount = 0\n",
    "                break\n",
    "            count = count + 1\n",
    "            continue\n",
    "        article = {}\n",
    "        article['title'] = content.title\n",
    "        article['text'] = content.text\n",
    "        article['link'] = content.url\n",
    "        article['published'] = content.publish_date.isoformat()\n",
    "        newsPaper['articles'].append(article)\n",
    "        print(count, \"articles downloaded from\", company, \" using newspaper, url: \", content.url)\n",
    "        count = count + 1\n",
    "        noneTypeCount = 0\n",
    "\n",
    "        data['newspapers'][company] = newsPaper\n",
    "        \n",
    "try:\n",
    "    with open('scraped_articles.json', 'w') as outfile:\n",
    "        json.dump(data, outfile)\n",
    "except Exception as e: print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
